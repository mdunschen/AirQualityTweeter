{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liverpool Speke Air\n",
      "TESTTEST\n",
      "8\n",
      "Liverpool Speke Air\n",
      "824277255526486016\n",
      "Liverpool Speke Air\n",
      "In reply to: TEST3\n",
      "18\n",
      "Liverpool Speke Air\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: <utf-8> -*-\n",
    "import urllib\n",
    "import urllib.request as request\n",
    "import re\n",
    "import html\n",
    "import sys, os\n",
    "sys.path.append(\"C:\\\\Program Files\\\\Anaconda3\\\\envs\\\\tensorflow\\\\lib\\\\site-packages\")\n",
    "import tweepy\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "urlstr = \"https://uk-air.defra.gov.uk/latest/currentlevels?view=site#L\"\n",
    "shorturlstr = \"https://goo.gl/ZpELjS\"\n",
    "\n",
    "urlWHO = \"http://apps.who.int/iris/bitstream/10665/69477/1/WHO_SDE_PHE_OEH_06.02_eng.pdf\"\n",
    "\n",
    "sitename = b'Liverpool'\n",
    "\n",
    "mgm3 = '\\u03BCgm\\u207B\\u00B3'\n",
    "O3, NO2, SO2, PM25, PM100 = \"O\\u2083\", \"NO\\u2082\", \"SO\\u2082\", \"PM\\u2082\\u2085\", \"PM\\u2081\\u2080\\u2080\"\n",
    "guides = {O3:100, NO2:200, SO2:20, PM25:25, PM100:50} # source: http://apps.who.int/iris/bitstream/10665/69477/1/WHO_SDE_PHE_OEH_06.02_eng.pdf  \n",
    "meansWHO = {O3:'8-hour', NO2:'1-hour', SO2:'10-minute', PM25:'24-hour', PM100:'24-hour'}\n",
    "meansDEFRA = {O3:'8-hour', NO2:'1-hour', SO2:'max 15-min', PM25:'24-hour', PM100:'24-hour'}\n",
    "\n",
    "\n",
    "def tweet(status, replyto=None):\n",
    "    if not status:\n",
    "        return\n",
    "    consumer_key, consumer_secret, access_token, access_token_secret = pickle.load(open(\"apikeys.bin\", \"rb\"))    \n",
    "\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    print(api.me().name)\n",
    "    print(status)\n",
    "    print(len(status))\n",
    "    print(api.me().name)\n",
    "    if replyto:\n",
    "        stat = api.update_status(status=status, in_reply_to_status_id=replyto.id)\n",
    "    else:\n",
    "        stat = api.update_status(status=status)\n",
    "    return stat\n",
    "    \n",
    "def compose(day, clock, reading):    \n",
    "    status = [\"%s, %s (%s)\" % (day, clock, mgm3)]\n",
    "    skeys = list(reading.keys())\n",
    "    skeys.sort()\n",
    "    for k in skeys:\n",
    "        status.append(\"%s: %.0f %s\" % (k, reading[k][0], reading[k][1]))\n",
    "    status.append(\"%s\" % shorturlstr)\n",
    "    status = '\\n'.join(status)\n",
    "    return status\n",
    "\n",
    "def composeAboveTweet(day, clock, above):\n",
    "    status = []\n",
    "    for k in above:\n",
    "        # count hours above\n",
    "        print(\"In composeAboveTweet\", k, above[k])\n",
    "        lday, lclock, lvalue = above[k][0]\n",
    "        if lday == day and lclock == clock:\n",
    "            stat = []\n",
    "            # count hours above\n",
    "            nhours = 1\n",
    "            for lday, lclock, lvalue in above[k][1:]:\n",
    "                if int(lclock[:lclock.index(':')]) + nhours == int(clock[:clock.index(':')]):\n",
    "                    nhours += 1\n",
    "                else:\n",
    "                    break\n",
    "            stat.append(\"@lpoolcouncil @DefraUKAir: %s above @WHO guide of %.0f%s (%s-mean) (%s) for %d hours (%s)\" % \n",
    "                        (k, guides[k], mgm3, meansWHO[k], urlWHO, nhours, shorturlstr))\n",
    "            stat.append(\"#AirPollution #Liverpool\")\n",
    "            if meansWHO[k] != meansDEFRA[k]:\n",
    "                stat.append(\"(Note #DEFRA data is %s-mean)\" % meansDEFRA[k])            \n",
    "            status.append('\\n'.join(stat))\n",
    "    return status\n",
    "        \n",
    "\n",
    "\n",
    "def scrape():\n",
    "    f = request.urlopen(urlstr)\n",
    "\n",
    "    r = f.read()\n",
    "    g = re.search(b\".*<tr>.*(%s.*?)</tr>\" % sitename, r, re.DOTALL)\n",
    "    #print(g.group(1))\n",
    "\n",
    "    # split into <td></td>\n",
    "    row = g.group(1)\n",
    "    #print(\"row = %s\\n\" % row)\n",
    "\n",
    "    # date and time\n",
    "    dategroups = re.search(b\".*<td>(.*?)<br.*?>(.*?)</td>\", row, re.DOTALL)\n",
    "    day = dategroups.group(1).decode(\"utf-8\")\n",
    "    clock = dategroups.group(2).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "    # data\n",
    "    cols = re.findall(b\"<span.*?>(.*?)</span>\", row, re.DOTALL)\n",
    "    assert len(cols) == 5\n",
    "    units = [O3, NO2, SO2, PM25, PM100]\n",
    "    datanums = []\n",
    "    for v in cols:\n",
    "        if b' ' in v:\n",
    "            value = float(v[:v.index(b' ')])\n",
    "        else:\n",
    "            value = float(v[:v.index(b'&')])\n",
    "        nv = v.replace(b'&nbsp;', b' ')\n",
    "        ix = re.match(b\".*?(\\(.*?\\))\", nv).group(1)\n",
    "        datanums.append((value, ix.decode(\"utf-8\")))\n",
    "\n",
    "    reading = dict(zip(units, datanums))\n",
    "    return day, clock, reading\n",
    "\n",
    "def loadReadings():\n",
    "    fall = \"allreadings.bin\"\n",
    "    allreadings = deque()\n",
    "    if os.path.isfile(fall):\n",
    "        allreadings = pickle.load(open(fall, \"rb\"))\n",
    "    return allreadings\n",
    "\n",
    "def pickleReadings(allreading):\n",
    "    fall = \"allreadings.bin\"\n",
    "    pickle.dump(allreadings, open(fall, \"wb\"))\n",
    "    \n",
    "def compareWHO(allreadings):\n",
    "    above = {}\n",
    "    for (day, clock, reading) in allreadings:\n",
    "        for k in guides:\n",
    "            if reading[k][0] > guides[k]:\n",
    "                if k not in above:\n",
    "                    above[k] = []\n",
    "                above[k].append((day,clock, reading[k][0]))\n",
    "    return above\n",
    "\n",
    "\n",
    "debug = False\n",
    "\n",
    "if debug:\n",
    "    stat = tweet(\"TESTTEST\")\n",
    "    print(stat.id)\n",
    "    tweet(\"In reply to: TEST3\", stat)\n",
    "\n",
    "else:\n",
    "    day, clock, reading = scrape()\n",
    "    status = compose(day, clock, reading)\n",
    "    stat = tweet(status)\n",
    "\n",
    "    allreadings = loadReadings()\n",
    "    allreadings.appendleft((day, clock, reading))\n",
    "    pickleReadings(allreadings)\n",
    "\n",
    "    # compare with WHO recommendations\n",
    "    r = compareWHO(allreadings)\n",
    "    if r:\n",
    "        stats = composeAboveTweet(day, clock, r)\n",
    "        for s in stats:\n",
    "            tweet(s, replyto=stat)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
